{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13204771,"sourceType":"datasetVersion","datasetId":8368893}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nprint(os.listdir(\"/kaggle/input/hc3-23\"))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:08.252995Z","iopub.execute_input":"2025-09-29T08:59:08.253341Z","iopub.status.idle":"2025-09-29T08:59:08.286757Z","shell.execute_reply.started":"2025-09-29T08:59:08.253310Z","shell.execute_reply":"2025-09-29T08:59:08.285422Z"}},"outputs":[{"name":"stdout","text":"['HC3.jsonl']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"file_path = \"/kaggle/input/hc3-23/HC3.jsonl\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:08.288789Z","iopub.execute_input":"2025-09-29T08:59:08.289112Z","iopub.status.idle":"2025-09-29T08:59:08.293298Z","shell.execute_reply.started":"2025-09-29T08:59:08.289086Z","shell.execute_reply":"2025-09-29T08:59:08.292377Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_json(file_path, lines=True, encoding='utf-8')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:08.294513Z","iopub.execute_input":"2025-09-29T08:59:08.294790Z","iopub.status.idle":"2025-09-29T08:59:12.490244Z","shell.execute_reply.started":"2025-09-29T08:59:08.294769Z","shell.execute_reply":"2025-09-29T08:59:12.489312Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"file_path = \"/kaggle/working/hc3-23.csv\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:12.492068Z","iopub.execute_input":"2025-09-29T08:59:12.492441Z","iopub.status.idle":"2025-09-29T08:59:12.497278Z","shell.execute_reply.started":"2025-09-29T08:59:12.492407Z","shell.execute_reply":"2025-09-29T08:59:12.496238Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df.to_csv(\"hc3-23.csv\", index=False) \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:12.498339Z","iopub.execute_input":"2025-09-29T08:59:12.498767Z","iopub.status.idle":"2025-09-29T08:59:15.450295Z","shell.execute_reply.started":"2025-09-29T08:59:12.498732Z","shell.execute_reply":"2025-09-29T08:59:15.448978Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df = pd.read_csv(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:15.452448Z","iopub.execute_input":"2025-09-29T08:59:15.452801Z","iopub.status.idle":"2025-09-29T08:59:16.337975Z","shell.execute_reply.started":"2025-09-29T08:59:15.452774Z","shell.execute_reply":"2025-09-29T08:59:16.336981Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:16.339008Z","iopub.execute_input":"2025-09-29T08:59:16.339314Z","iopub.status.idle":"2025-09-29T08:59:16.362545Z","shell.execute_reply.started":"2025-09-29T08:59:16.339290Z","shell.execute_reply":"2025-09-29T08:59:16.361586Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  Why is every book I hear about a \" NY Times # ...   \n1  If salt is so bad for cars , why do we use it ...   \n2  Why do we still have SD TV channels when HD lo...   \n3  Why has nobody assassinated Kim Jong - un He i...   \n4  How was airplane technology able to advance so...   \n\n                                       human_answers  \\\n0  ['Basically there are many categories of \" Bes...   \n1  ['salt is good for not dying in car crashes an...   \n2  [\"The way it works is that old TV stations got...   \n3  [\"You ca n't just go around assassinating the ...   \n4  ['Wanting to kill the shit out of Germans driv...   \n\n                                     chatgpt_answers  index       source  \n0  ['There are many different best seller lists t...    NaN  reddit_eli5  \n1  [\"Salt is used on roads to help melt ice and s...    NaN  reddit_eli5  \n2  [\"There are a few reasons why we still have SD...    NaN  reddit_eli5  \n3  ['It is generally not acceptable or ethical to...    NaN  reddit_eli5  \n4  ['After the Wright Brothers made the first pow...    NaN  reddit_eli5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>human_answers</th>\n      <th>chatgpt_answers</th>\n      <th>index</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Why is every book I hear about a \" NY Times # ...</td>\n      <td>['Basically there are many categories of \" Bes...</td>\n      <td>['There are many different best seller lists t...</td>\n      <td>NaN</td>\n      <td>reddit_eli5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>If salt is so bad for cars , why do we use it ...</td>\n      <td>['salt is good for not dying in car crashes an...</td>\n      <td>[\"Salt is used on roads to help melt ice and s...</td>\n      <td>NaN</td>\n      <td>reddit_eli5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why do we still have SD TV channels when HD lo...</td>\n      <td>[\"The way it works is that old TV stations got...</td>\n      <td>[\"There are a few reasons why we still have SD...</td>\n      <td>NaN</td>\n      <td>reddit_eli5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Why has nobody assassinated Kim Jong - un He i...</td>\n      <td>[\"You ca n't just go around assassinating the ...</td>\n      <td>['It is generally not acceptable or ethical to...</td>\n      <td>NaN</td>\n      <td>reddit_eli5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How was airplane technology able to advance so...</td>\n      <td>['Wanting to kill the shit out of Germans driv...</td>\n      <td>['After the Wright Brothers made the first pow...</td>\n      <td>NaN</td>\n      <td>reddit_eli5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"\nprint(\"=\"*80)\nprint(\"PHASE 1: DATASET IMPORT AND INSPECTION\")\nprint(\"=\"*80)\n\n# Check dataset size\nprint(f\"\\nDataset loaded successfully!\")\nprint(f\"Total number of rows: {len(df)}\")\nprint(f\"Total number of columns: {len(df.columns)}\")\n\n# Display column names\nprint(\"\\n\" + \"-\"*80)\nprint(\"Column Names:\")\nprint(\"-\"*80)\nfor i, col in enumerate(df.columns):\n    print(f\"Column {i}: {col}\")\n\n# Display first few rows\nprint(\"\\n\" + \"-\"*80)\nprint(\"First 5 Rows of Dataset:\")\nprint(\"-\"*80)\nprint(df.head())\n\n# Check data types\nprint(\"\\n\" + \"-\"*80)\nprint(\"Data Types of Each Column:\")\nprint(\"-\"*80)\nprint(df.dtypes)\n\n# Check for missing values\nprint(\"\\n\" + \"-\"*80)\nprint(\"Missing Values Count:\")\nprint(\"-\"*80)\nprint(df.isnull().sum())\n\n# Identify human and AI answer columns\nprint(\"\\n\" + \"-\"*80)\nprint(\"IDENTIFYING HUMAN AND AI ANSWER COLUMNS:\")\nprint(\"-\"*80)\n\n# Based on your sample output, let's check what columns contain the answers\nprint(\"\\nSample from each column:\\n\")\nfor i, col in enumerate(df.columns):\n    print(f\"Column {i} ({col}):\")\n    print(f\"  Type: {type(df.iloc[0, i])}\")\n    print(f\"  Sample: {df.iloc[0, i]}\")\n    print()\n\n# Specifically check the answer columns (columns 1 and 2 based on your output)\nif len(df.columns) > 2:\n    print(\"\\n\" + \"-\"*80)\n    print(\"Human Answers Column (Column 1):\")\n    print(\"-\"*80)\n    print(f\"Column name: {df.columns[1]}\")\n    print(f\"Data type: {df[df.columns[1]].dtype}\")\n    print(f\"Sample entry: {df.iloc[0, 1]}\")\n    \n    print(\"\\n\" + \"-\"*80)\n    print(\"AI Answers Column (Column 2):\")\n    print(\"-\"*80)\n    print(f\"Column name: {df.columns[2]}\")\n    print(f\"Data type: {df[df.columns[2]].dtype}\")\n    print(f\"Sample entry: {df.iloc[0, 2]}\")\n\n# Final verification\nprint(\"\\n\" + \"=\"*80)\nprint(\"VERIFICATION SUMMARY:\")\nprint(\"=\"*80)\nprint(f\"✓ Dataset loaded: {len(df)} rows × {len(df.columns)} columns\")\nprint(f\"✓ Human answers are in column: {df.columns[1]}\")\nprint(f\"✓ AI answers are in column: {df.columns[2]}\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:16.363459Z","iopub.execute_input":"2025-09-29T08:59:16.363757Z","iopub.status.idle":"2025-09-29T08:59:16.396897Z","shell.execute_reply.started":"2025-09-29T08:59:16.363725Z","shell.execute_reply":"2025-09-29T08:59:16.395598Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nPHASE 1: DATASET IMPORT AND INSPECTION\n================================================================================\n\nDataset loaded successfully!\nTotal number of rows: 24322\nTotal number of columns: 5\n\n--------------------------------------------------------------------------------\nColumn Names:\n--------------------------------------------------------------------------------\nColumn 0: question\nColumn 1: human_answers\nColumn 2: chatgpt_answers\nColumn 3: index\nColumn 4: source\n\n--------------------------------------------------------------------------------\nFirst 5 Rows of Dataset:\n--------------------------------------------------------------------------------\n                                            question  \\\n0  Why is every book I hear about a \" NY Times # ...   \n1  If salt is so bad for cars , why do we use it ...   \n2  Why do we still have SD TV channels when HD lo...   \n3  Why has nobody assassinated Kim Jong - un He i...   \n4  How was airplane technology able to advance so...   \n\n                                       human_answers  \\\n0  ['Basically there are many categories of \" Bes...   \n1  ['salt is good for not dying in car crashes an...   \n2  [\"The way it works is that old TV stations got...   \n3  [\"You ca n't just go around assassinating the ...   \n4  ['Wanting to kill the shit out of Germans driv...   \n\n                                     chatgpt_answers  index       source  \n0  ['There are many different best seller lists t...    NaN  reddit_eli5  \n1  [\"Salt is used on roads to help melt ice and s...    NaN  reddit_eli5  \n2  [\"There are a few reasons why we still have SD...    NaN  reddit_eli5  \n3  ['It is generally not acceptable or ethical to...    NaN  reddit_eli5  \n4  ['After the Wright Brothers made the first pow...    NaN  reddit_eli5  \n\n--------------------------------------------------------------------------------\nData Types of Each Column:\n--------------------------------------------------------------------------------\nquestion            object\nhuman_answers       object\nchatgpt_answers     object\nindex              float64\nsource              object\ndtype: object\n\n--------------------------------------------------------------------------------\nMissing Values Count:\n--------------------------------------------------------------------------------\nquestion               0\nhuman_answers          0\nchatgpt_answers        0\nindex              21801\nsource                 0\ndtype: int64\n\n--------------------------------------------------------------------------------\nIDENTIFYING HUMAN AND AI ANSWER COLUMNS:\n--------------------------------------------------------------------------------\n\nSample from each column:\n\nColumn 0 (question):\n  Type: <class 'str'>\n  Sample: Why is every book I hear about a \" NY Times # 1 Best Seller \" ? ELI5 : Why is every book I hear about a \" NY Times # 1 Best Seller \" ? Should n't there only be one \" # 1 \" best seller ? Please explain like I'm five.\n\nColumn 1 (human_answers):\n  Type: <class 'str'>\n  Sample: ['Basically there are many categories of \" Best Seller \" . Replace \" Best Seller \" by something like \" Oscars \" and every \" best seller \" book is basically an \" oscar - winning \" book . May not have won the \" Best film \" , but even if you won the best director or best script , you \\'re still an \" oscar - winning \" film . Same thing for best sellers . Also , IIRC the rankings change every week or something like that . Some you might not be best seller one week , but you may be the next week . I guess even if you do n\\'t stay there for long , you still achieved the status . Hence , # 1 best seller .', \"If you 're hearing about it , it 's because it was a very good or very well - publicized book ( or both ) , and almost every good or well - publicized book will be # 1 on the NY Times bestseller list for at least a little bit . Kindof like how almost every big or good movies are # 1 at the box office on their opening weekend .\", \"One reason is lots of catagories . However , how the NY Times calculates its best seller list is n't comprehensive , and is pretty well understood by publishers . So publishers can [ buy a few books ] ( URL_0 ) in the right bookstores and send a book to the top of the list for at least a week .\"]\n\nColumn 2 (chatgpt_answers):\n  Type: <class 'str'>\n  Sample: ['There are many different best seller lists that are published by various organizations, and the New York Times is just one of them. The New York Times best seller list is a weekly list that ranks the best-selling books in the United States based on sales data from a number of different retailers. The list is published in the New York Times newspaper and is widely considered to be one of the most influential best seller lists in the book industry. \\nIt\\'s important to note that the New York Times best seller list is not the only best seller list out there, and there are many other lists that rank the top-selling books in different categories or in different countries. So it\\'s possible that a book could be a best seller on one list but not on another. \\nAdditionally, the term \"best seller\" is often used more broadly to refer to any book that is selling well, regardless of whether it is on a specific best seller list or not. So it\\'s possible that you may hear about a book being a \"best seller\" even if it is not specifically ranked as a number one best seller on the New York Times list or any other list.']\n\nColumn 3 (index):\n  Type: <class 'numpy.float64'>\n  Sample: nan\n\nColumn 4 (source):\n  Type: <class 'str'>\n  Sample: reddit_eli5\n\n\n--------------------------------------------------------------------------------\nHuman Answers Column (Column 1):\n--------------------------------------------------------------------------------\nColumn name: human_answers\nData type: object\nSample entry: ['Basically there are many categories of \" Best Seller \" . Replace \" Best Seller \" by something like \" Oscars \" and every \" best seller \" book is basically an \" oscar - winning \" book . May not have won the \" Best film \" , but even if you won the best director or best script , you \\'re still an \" oscar - winning \" film . Same thing for best sellers . Also , IIRC the rankings change every week or something like that . Some you might not be best seller one week , but you may be the next week . I guess even if you do n\\'t stay there for long , you still achieved the status . Hence , # 1 best seller .', \"If you 're hearing about it , it 's because it was a very good or very well - publicized book ( or both ) , and almost every good or well - publicized book will be # 1 on the NY Times bestseller list for at least a little bit . Kindof like how almost every big or good movies are # 1 at the box office on their opening weekend .\", \"One reason is lots of catagories . However , how the NY Times calculates its best seller list is n't comprehensive , and is pretty well understood by publishers . So publishers can [ buy a few books ] ( URL_0 ) in the right bookstores and send a book to the top of the list for at least a week .\"]\n\n--------------------------------------------------------------------------------\nAI Answers Column (Column 2):\n--------------------------------------------------------------------------------\nColumn name: chatgpt_answers\nData type: object\nSample entry: ['There are many different best seller lists that are published by various organizations, and the New York Times is just one of them. The New York Times best seller list is a weekly list that ranks the best-selling books in the United States based on sales data from a number of different retailers. The list is published in the New York Times newspaper and is widely considered to be one of the most influential best seller lists in the book industry. \\nIt\\'s important to note that the New York Times best seller list is not the only best seller list out there, and there are many other lists that rank the top-selling books in different categories or in different countries. So it\\'s possible that a book could be a best seller on one list but not on another. \\nAdditionally, the term \"best seller\" is often used more broadly to refer to any book that is selling well, regardless of whether it is on a specific best seller list or not. So it\\'s possible that you may hear about a book being a \"best seller\" even if it is not specifically ranked as a number one best seller on the New York Times list or any other list.']\n\n================================================================================\nVERIFICATION SUMMARY:\n================================================================================\n✓ Dataset loaded: 24322 rows × 5 columns\n✓ Human answers are in column: human_answers\n✓ AI answers are in column: chatgpt_answers\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"PHASE 2: SELECT RELEVANT DATA AND CLEAN MINIMAL NOISE\")\nprint(\"=\"*80)\n\n# Step 1: Keep only relevant columns (human_answers and chatgpt_answers)\nprint(\"\\nStep 1: Selecting relevant columns...\")\ndf_clean = df[['human_answers', 'chatgpt_answers']].copy()\nprint(f\"✓ Selected columns: {df_clean.columns.tolist()}\")\nprint(f\"✓ Shape after column selection: {df_clean.shape}\")\n\n# Step 2: Remove rows with missing values\nprint(\"\\nStep 2: Removing rows with missing values...\")\nprint(f\"Missing values before cleaning:\")\nprint(df_clean.isnull().sum())\ndf_clean = df_clean.dropna()\nprint(f\"✓ Shape after removing missing values: {df_clean.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:16.398192Z","iopub.execute_input":"2025-09-29T08:59:16.398893Z","iopub.status.idle":"2025-09-29T08:59:16.435874Z","shell.execute_reply.started":"2025-09-29T08:59:16.398867Z","shell.execute_reply":"2025-09-29T08:59:16.434767Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nPHASE 2: SELECT RELEVANT DATA AND CLEAN MINIMAL NOISE\n================================================================================\n\nStep 1: Selecting relevant columns...\n✓ Selected columns: ['human_answers', 'chatgpt_answers']\n✓ Shape after column selection: (24322, 2)\n\nStep 2: Removing rows with missing values...\nMissing values before cleaning:\nhuman_answers      0\nchatgpt_answers    0\ndtype: int64\n✓ Shape after removing missing values: (24322, 2)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\n# Step 3: Convert string representation of lists to actual lists and flatten\nprint(\"\\nStep 3: Converting string lists to actual lists and flattening...\")\n\nimport ast\n\ndef flatten_list_column(text):\n    \"\"\"\n    Convert string representation of list to actual list,\n    then join all elements into a single string\n    \"\"\"\n    try:\n        # Convert string representation of list to actual list\n        text_list = ast.literal_eval(text)\n        # Join all elements with space\n        flattened = ' '.join(text_list)\n        return flattened\n    except:\n        # If it's already a string, return as is\n        return str(text)\n\ndf_clean['human_answers'] = df_clean['human_answers'].apply(flatten_list_column)\ndf_clean['chatgpt_answers'] = df_clean['chatgpt_answers'].apply(flatten_list_column)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:16.436862Z","iopub.execute_input":"2025-09-29T08:59:16.437147Z","iopub.status.idle":"2025-09-29T08:59:17.723713Z","shell.execute_reply.started":"2025-09-29T08:59:16.437123Z","shell.execute_reply":"2025-09-29T08:59:17.722525Z"}},"outputs":[{"name":"stdout","text":"\nStep 3: Converting string lists to actual lists and flattening...\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"\nprint(f\"✓ Lists flattened into single strings\")\n\n# Step 4: Replace literal \\n with spaces and strip whitespace\nprint(\"\\nStep 4: Cleaning newline characters and stripping whitespace...\")\ndf_clean['human_answers'] = df_clean['human_answers'].str.replace('\\\\n', ' ', regex=False)\ndf_clean['chatgpt_answers'] = df_clean['chatgpt_answers'].str.replace('\\\\n', ' ', regex=False)\n\ndf_clean['human_answers'] = df_clean['human_answers'].str.strip()\ndf_clean['chatgpt_answers'] = df_clean['chatgpt_answers'].str.strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:17.724673Z","iopub.execute_input":"2025-09-29T08:59:17.724947Z","iopub.status.idle":"2025-09-29T08:59:17.864736Z","shell.execute_reply.started":"2025-09-29T08:59:17.724925Z","shell.execute_reply":"2025-09-29T08:59:17.863617Z"}},"outputs":[{"name":"stdout","text":"✓ Lists flattened into single strings\n\nStep 4: Cleaning newline characters and stripping whitespace...\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"\nprint(f\"✓ Newline characters replaced with spaces\")\nprint(f\"✓ Whitespace stripped\")\n\n# Step 5: Verify that we're NOT removing punctuation, stopwords, or changing case\nprint(\"\\nStep 5: Verification - preserving important cues...\")\nprint(\"✓ Punctuation: PRESERVED\")\nprint(\"✓ Stopwords: PRESERVED\")\nprint(\"✓ Capitalization: PRESERVED\")\nprint(\"✓ All text features remain intact for AI detection\")\n\n# Final verification\nprint(\"\\n\" + \"-\"*80)\nprint(\"SAMPLE DATA AFTER CLEANING:\")\nprint(\"-\"*80)\nprint(f\"\\nHuman answer example (first 500 chars):\")\nprint(df_clean['human_answers'].iloc[0][:500])\nprint(f\"\\nAI answer example (first 500 chars):\")\nprint(df_clean['chatgpt_answers'].iloc[0][:500])\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"DATA STATISTICS:\")\nprint(\"-\"*80)\nprint(f\"Total rows after cleaning: {len(df_clean)}\")\nprint(f\"\\nHuman answers - Average length: {df_clean['human_answers'].str.len().mean():.0f} characters\")\nprint(f\"AI answers - Average length: {df_clean['chatgpt_answers'].str.len().mean():.0f} characters\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 2 COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"✓ Final dataset shape: {df_clean.shape}\")\nprint(f\"✓ Ready for labeling in Phase 3\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:17.868104Z","iopub.execute_input":"2025-09-29T08:59:17.868374Z","iopub.status.idle":"2025-09-29T08:59:17.912011Z","shell.execute_reply.started":"2025-09-29T08:59:17.868354Z","shell.execute_reply":"2025-09-29T08:59:17.910848Z"}},"outputs":[{"name":"stdout","text":"✓ Newline characters replaced with spaces\n✓ Whitespace stripped\n\nStep 5: Verification - preserving important cues...\n✓ Punctuation: PRESERVED\n✓ Stopwords: PRESERVED\n✓ Capitalization: PRESERVED\n✓ All text features remain intact for AI detection\n\n--------------------------------------------------------------------------------\nSAMPLE DATA AFTER CLEANING:\n--------------------------------------------------------------------------------\n\nHuman answer example (first 500 chars):\nBasically there are many categories of \" Best Seller \" . Replace \" Best Seller \" by something like \" Oscars \" and every \" best seller \" book is basically an \" oscar - winning \" book . May not have won the \" Best film \" , but even if you won the best director or best script , you 're still an \" oscar - winning \" film . Same thing for best sellers . Also , IIRC the rankings change every week or something like that . Some you might not be best seller one week , but you may be the next week . I gues\n\nAI answer example (first 500 chars):\nThere are many different best seller lists that are published by various organizations, and the New York Times is just one of them. The New York Times best seller list is a weekly list that ranks the best-selling books in the United States based on sales data from a number of different retailers. The list is published in the New York Times newspaper and is widely considered to be one of the most influential best seller lists in the book industry. \nIt's important to note that the New York Times b\n\n--------------------------------------------------------------------------------\nDATA STATISTICS:\n--------------------------------------------------------------------------------\nTotal rows after cleaning: 24322\n\nHuman answers - Average length: 1640 characters\nAI answers - Average length: 1117 characters\n\n================================================================================\nPHASE 2 COMPLETE!\n================================================================================\n✓ Final dataset shape: (24322, 2)\n✓ Ready for labeling in Phase 3\n================================================================================\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"df_clean['chatgpt_answers'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:17.912872Z","iopub.execute_input":"2025-09-29T08:59:17.913130Z","iopub.status.idle":"2025-09-29T08:59:17.920485Z","shell.execute_reply.started":"2025-09-29T08:59:17.913109Z","shell.execute_reply":"2025-09-29T08:59:17.919609Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"\"Salt is used on roads to help melt ice and snow and improve traction during the winter months. When it's cold outside, water can freeze on the roads and make them very slippery, which can be dangerous for cars and people. Salt helps to melt the ice and snow by lowering the freezing point of water, which means that it can help keep the roads clear and safe to travel on. \\nThere are other options for melting ice and snow on roads, such as using chemicals like calcium chloride or magnesium chloride, or using mechanical methods like plows or sand. However, salt is often the most effective and affordable option for many communities, especially when it's used in combination with other methods. \\nIt's important to note that while salt can be helpful for making roads safer during the winter, it can also have negative effects on the environment and on the cars themselves. Salt can cause corrosion on metal surfaces, including cars, and it can also harm plants and animals if it washes into nearby waterways. However, despite these potential downsides, many communities continue to use salt as a way to keep roads clear and safe during the winter.\""},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"df_clean['chatgpt_answers'].isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:17.921426Z","iopub.execute_input":"2025-09-29T08:59:17.921845Z","iopub.status.idle":"2025-09-29T08:59:17.945697Z","shell.execute_reply.started":"2025-09-29T08:59:17.921812Z","shell.execute_reply":"2025-09-29T08:59:17.944431Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"PHASE 3: LABEL DATA FOR CLASSIFICATION\")\nprint(\"=\"*80)\n\n# Step 1: Create labeled dataset - Human text labeled as 0\nprint(\"\\nStep 1: Creating dataset with human text (label = 0)...\")\nhuman_data = pd.DataFrame({\n    'text': df_clean['human_answers'],\n    'label': 0\n})\nprint(f\"✓ Human samples created: {len(human_data)}\")\n\n# Step 2: Create labeled dataset - AI text labeled as 1\nprint(\"\\nStep 2: Creating dataset with AI text (label = 1)...\")\nai_data = pd.DataFrame({\n    'text': df_clean['chatgpt_answers'],\n    'label': 1\n})\nprint(f\"✓ AI samples created: {len(ai_data)}\")\n\n# Step 3: Combine both datasets\nprint(\"\\nStep 3: Combining human and AI datasets...\")\ncombined_data = pd.concat([human_data, ai_data], ignore_index=True)\nprint(f\"✓ Combined dataset size: {len(combined_data)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:17.946824Z","iopub.execute_input":"2025-09-29T08:59:17.947133Z","iopub.status.idle":"2025-09-29T08:59:17.973291Z","shell.execute_reply.started":"2025-09-29T08:59:17.947109Z","shell.execute_reply":"2025-09-29T08:59:17.972258Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nPHASE 3: LABEL DATA FOR CLASSIFICATION\n================================================================================\n\nStep 1: Creating dataset with human text (label = 0)...\n✓ Human samples created: 24322\n\nStep 2: Creating dataset with AI text (label = 1)...\n✓ AI samples created: 24322\n\nStep 3: Combining human and AI datasets...\n✓ Combined dataset size: 48644\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"\n# Step 4: Check label distribution before shuffling\nprint(\"\\nStep 4: Checking label distribution...\")\nprint(combined_data['label'].value_counts())\nprint(f\"\\nLabel 0 (Human): {(combined_data['label'] == 0).sum()} samples\")\nprint(f\"Label 1 (AI): {(combined_data['label'] == 1).sum()} samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:17.974918Z","iopub.execute_input":"2025-09-29T08:59:17.975800Z","iopub.status.idle":"2025-09-29T08:59:17.991007Z","shell.execute_reply.started":"2025-09-29T08:59:17.975769Z","shell.execute_reply":"2025-09-29T08:59:17.989849Z"}},"outputs":[{"name":"stdout","text":"\nStep 4: Checking label distribution...\nlabel\n0    24322\n1    24322\nName: count, dtype: int64\n\nLabel 0 (Human): 24322 samples\nLabel 1 (AI): 24322 samples\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Step 5: Shuffle the dataset to avoid order biases\nprint(\"\\nStep 5: Shuffling dataset to avoid order biases...\")\nfrom sklearn.utils import shuffle\ncombined_data = shuffle(combined_data, random_state=42).reset_index(drop=True)\nprint(f\"✓ Dataset shuffled with random_state=42\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:17.992324Z","iopub.execute_input":"2025-09-29T08:59:17.992989Z","iopub.status.idle":"2025-09-29T08:59:19.722184Z","shell.execute_reply.started":"2025-09-29T08:59:17.992960Z","shell.execute_reply":"2025-09-29T08:59:19.721190Z"}},"outputs":[{"name":"stdout","text":"\nStep 5: Shuffling dataset to avoid order biases...\n✓ Dataset shuffled with random_state=42\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Final verification\nprint(\"\\n\" + \"-\"*80)\nprint(\"SAMPLE DATA AFTER LABELING AND SHUFFLING:\")\nprint(\"-\"*80)\nprint(f\"\\nFirst 5 rows:\")\nprint(combined_data.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:19.723422Z","iopub.execute_input":"2025-09-29T08:59:19.724145Z","iopub.status.idle":"2025-09-29T08:59:19.733333Z","shell.execute_reply.started":"2025-09-29T08:59:19.724114Z","shell.execute_reply":"2025-09-29T08:59:19.731817Z"}},"outputs":[{"name":"stdout","text":"\n--------------------------------------------------------------------------------\nSAMPLE DATA AFTER LABELING AND SHUFFLING:\n--------------------------------------------------------------------------------\n\nFirst 5 rows:\n                                                text  label\n0  Its a giant phonebook that provides informatio...      0\n1  Pi, denoted by the symbol \"π,\" is a mathematic...      1\n2  jumpup has decent explanations but misses quit...      0\n3  Berkshire Hathaway is a large, diversified con...      1\n4  The Voyager satellites have several features t...      1\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"FINAL STATISTICS:\")\nprint(\"-\"*80)\nprint(f\"Total samples: {len(combined_data)}\")\nprint(f\"Human samples (label=0): {(combined_data['label'] == 0).sum()}\")\nprint(f\"AI samples (label=1): {(combined_data['label'] == 1).sum()}\")\nprint(f\"Class balance: {(combined_data['label'] == 0).sum() / len(combined_data) * 100:.1f}% human, {(combined_data['label'] == 1).sum() / len(combined_data) * 100:.1f}% AI\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:19.734615Z","iopub.execute_input":"2025-09-29T08:59:19.735137Z","iopub.status.idle":"2025-09-29T08:59:19.755845Z","shell.execute_reply.started":"2025-09-29T08:59:19.735102Z","shell.execute_reply":"2025-09-29T08:59:19.754624Z"}},"outputs":[{"name":"stdout","text":"\n--------------------------------------------------------------------------------\nFINAL STATISTICS:\n--------------------------------------------------------------------------------\nTotal samples: 48644\nHuman samples (label=0): 24322\nAI samples (label=1): 24322\nClass balance: 50.0% human, 50.0% AI\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# combined_data['text'][1]\n# 'Pi, denoted by the symbol \"π,\" is a mathematical constant that represents the ratio of the circumference of a circle to its diameter. It is an important number in mathematics because it appears in many different formulas and is used to calculate various properties of circles and other circular objects.\\n\\nIf Pi were to somehow \"terminate,\" meaning that it stopped being an infinite decimal and instead became a finite number, it would have significant effects on mathematics. For example, many formulas that involve Pi would no longer be accurate because they rely on Pi being an infinite decimal. This could lead to problems in many areas of mathematics and engineering that use these formulas to make calculations and predictions.\\n\\nIt\\'s important to note that Pi is an irrational number, which means that it cannot be expressed as a simple fraction and its decimal representation goes on indefinitely without repeating. This means that Pi will never terminate and will always be an infinite decimal.\\n\\nI hope this helps to explain the importance of Pi in mathematics!'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:19.756861Z","iopub.execute_input":"2025-09-29T08:59:19.757112Z","iopub.status.idle":"2025-09-29T08:59:19.772779Z","shell.execute_reply.started":"2025-09-29T08:59:19.757092Z","shell.execute_reply":"2025-09-29T08:59:19.771748Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"combined_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:19.773831Z","iopub.execute_input":"2025-09-29T08:59:19.774131Z","iopub.status.idle":"2025-09-29T08:59:19.799429Z","shell.execute_reply.started":"2025-09-29T08:59:19.774109Z","shell.execute_reply":"2025-09-29T08:59:19.798560Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  Its a giant phonebook that provides informatio...      0\n1  Pi, denoted by the symbol \"π,\" is a mathematic...      1\n2  jumpup has decent explanations but misses quit...      0\n3  Berkshire Hathaway is a large, diversified con...      1\n4  The Voyager satellites have several features t...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Its a giant phonebook that provides informatio...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pi, denoted by the symbol \"π,\" is a mathematic...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>jumpup has decent explanations but misses quit...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Berkshire Hathaway is a large, diversified con...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Voyager satellites have several features t...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.model_selection import train_test_split\n\n# Step 1: Define the cleaning function\ndef minimal_clean(text):\n    \"\"\"\n    Minimal cleaning that preserves AI vs human detection cues\n    \"\"\"\n    # Replace escape characters with space\n    text = text.replace('\\\\n', ' ').replace('\\\\t', ' ').replace('\\\\r', ' ')\n    # Remove escaped quotes\n    text = text.replace(\"\\\\'\", \"'\").replace('\\\\\"', '\"')\n    # Normalize whitespace\n    text = re.sub(r'\\s+', ' ', text)\n    # Strip leading/trailing space\n    text = text.strip()\n    return text\n\n# Step 2: Apply cleaning to your text column\ncombined_data['text'] = combined_data['text'].apply(minimal_clean)\n\n# Step 3: Remove any empty texts after cleaning\ncombined_data = combined_data[combined_data['text'].str.len() > 0]\n\n# Step 4: Check label distribution\nprint(\"Label distribution:\")\nprint(combined_data['label'].value_counts())\nprint(f\"\\nTotal samples: {len(combined_data)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:19.800353Z","iopub.execute_input":"2025-09-29T08:59:19.800700Z","iopub.status.idle":"2025-09-29T08:59:24.737948Z","shell.execute_reply.started":"2025-09-29T08:59:19.800632Z","shell.execute_reply":"2025-09-29T08:59:24.736814Z"}},"outputs":[{"name":"stdout","text":"Label distribution:\nlabel\n0    24322\n1    23865\nName: count, dtype: int64\n\nTotal samples: 48187\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"\n# Step 5: Check text length distribution (optional but recommended)\ncombined_data['text_length'] = combined_data['text'].str.len()\nprint(f\"\\nText length stats:\")\nprint(combined_data['text_length'].describe())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:24.739080Z","iopub.execute_input":"2025-09-29T08:59:24.739333Z","iopub.status.idle":"2025-09-29T08:59:24.784398Z","shell.execute_reply.started":"2025-09-29T08:59:24.739313Z","shell.execute_reply":"2025-09-29T08:59:24.783339Z"}},"outputs":[{"name":"stdout","text":"\nText length stats:\ncount    48187.000000\nmean      1389.988794\nstd       1166.378832\nmin          5.000000\n25%        774.000000\n50%       1106.000000\n75%       1572.000000\nmax      37159.000000\nName: text_length, dtype: float64\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"combined_data.head(3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:24.785435Z","iopub.execute_input":"2025-09-29T08:59:24.785759Z","iopub.status.idle":"2025-09-29T08:59:24.799048Z","shell.execute_reply.started":"2025-09-29T08:59:24.785728Z","shell.execute_reply":"2025-09-29T08:59:24.797945Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                                                text  label  text_length\n0  Its a giant phonebook that provides informatio...      0         2469\n1  Pi, denoted by the symbol \"π,\" is a mathematic...      1         1065\n2  jumpup has decent explanations but misses quit...      0         5047","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>text_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Its a giant phonebook that provides informatio...</td>\n      <td>0</td>\n      <td>2469</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Pi, denoted by the symbol \"π,\" is a mathematic...</td>\n      <td>1</td>\n      <td>1065</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>jumpup has decent explanations but misses quit...</td>\n      <td>0</td>\n      <td>5047</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"FILTERING TEXT BY LENGTH (BEFORE SPLITTING)\")\nprint(\"=\"*80)\n\n# Check current length distribution\nprint(\"\\nStep 1: Checking current text length distribution...\")\n\ncombined_data['text_length'] = combined_data['text'].str.len()\nprint(f\"Before filtering: {len(combined_data)} samples\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:24.800143Z","iopub.execute_input":"2025-09-29T08:59:24.800928Z","iopub.status.idle":"2025-09-29T08:59:24.847294Z","shell.execute_reply.started":"2025-09-29T08:59:24.800899Z","shell.execute_reply":"2025-09-29T08:59:24.846196Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nFILTERING TEXT BY LENGTH (BEFORE SPLITTING)\n================================================================================\n\nStep 1: Checking current text length distribution...\nBefore filtering: 48187 samples\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"combined_data['text_length']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:24.848249Z","iopub.execute_input":"2025-09-29T08:59:24.848632Z","iopub.status.idle":"2025-09-29T08:59:24.867688Z","shell.execute_reply.started":"2025-09-29T08:59:24.848604Z","shell.execute_reply":"2025-09-29T08:59:24.866724Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0        2469\n1        1065\n2        5047\n3        1072\n4        1013\n         ... \n48639    1396\n48640    1511\n48641     584\n48642     619\n48643    2988\nName: text_length, Length: 48187, dtype: int64"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"\n# Filter for texts under 320 characters\nprint(\"\\nStep 2: Filtering texts to keep only those under 320 characters...\")\nprint(f\"Before filtering: {len(combined_data)} samples\")\nprint(f\"After filtering: {len(combined_data)} samples\")\nprint(f\":{len(combined_data[combined_data['text_length'] > 320])} samples\")\nprint(f\":{len(combined_data[combined_data['text_length'] > 500])} samples\")\nprint(f\":{len(combined_data[combined_data['text_length'] > 1200])} samples\")\ncombined_data_copy= combined_data[combined_data['text_length'] < 1000].copy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:24.869002Z","iopub.execute_input":"2025-09-29T08:59:24.869843Z","iopub.status.idle":"2025-09-29T08:59:24.905123Z","shell.execute_reply.started":"2025-09-29T08:59:24.869806Z","shell.execute_reply":"2025-09-29T08:59:24.904208Z"}},"outputs":[{"name":"stdout","text":"\nStep 2: Filtering texts to keep only those under 320 characters...\nBefore filtering: 48187 samples\nAfter filtering: 48187 samples\n:45663 samples\n:43163 samples\n:20703 samples\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"from sklearn.utils import resample\n\n# Separate majority and minority classes\ndf_majority = combined_data_copy[combined_data_copy['label'] == 1]\ndf_minority = combined_data_copy[combined_data_copy['label'] == 0]\n\n# Downsample majority class (1) to match minority (0)\ndf_majority_downsampled = resample(\n    df_majority,\n    replace=False,             # no replacement\n    n_samples=len(df_minority), # match minority\n    random_state=42\n)\n\n# Combine back into a balanced dataset\nbalanced_data = pd.concat([df_majority_downsampled, df_minority])\n\n# Shuffle the dataset\nbalanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Verify\nprint(balanced_data['label'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:24.906422Z","iopub.execute_input":"2025-09-29T08:59:24.906827Z","iopub.status.idle":"2025-09-29T08:59:24.933452Z","shell.execute_reply.started":"2025-09-29T08:59:24.906796Z","shell.execute_reply":"2025-09-29T08:59:24.932420Z"}},"outputs":[{"name":"stdout","text":"label\n0    9853\n1    9853\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":28},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"combined_data_copy.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:24.934478Z","iopub.execute_input":"2025-09-29T08:59:24.935002Z","iopub.status.idle":"2025-09-29T08:59:24.944319Z","shell.execute_reply.started":"2025-09-29T08:59:24.934972Z","shell.execute_reply":"2025-09-29T08:59:24.943316Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                                                 text  label  text_length\n6   It is generally a good idea to use sponsorship...      1          793\n9   The World Cup and the Olympics can bring econo...      1          850\n11  A newton metre is a unit of torque (also calle...      0           77\n14  Citing the Yahoo Finance Help page, Beta: The ...      0          301\n15  Hi. Thanks for the queryYes, you have taken a ...      0          690","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>text_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>It is generally a good idea to use sponsorship...</td>\n      <td>1</td>\n      <td>793</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>The World Cup and the Olympics can bring econo...</td>\n      <td>1</td>\n      <td>850</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>A newton metre is a unit of torque (also calle...</td>\n      <td>0</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Citing the Yahoo Finance Help page, Beta: The ...</td>\n      <td>0</td>\n      <td>301</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Hi. Thanks for the queryYes, you have taken a ...</td>\n      <td>0</td>\n      <td>690</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# Quick check before filtering\nprint(f\"Samples under 320 chars: {(balanced_data['text'].str.len() <= 320).sum()}\")\nprint(f\"Samples over 320 chars: {(balanced_data['text'].str.len() > 320).sum()}\")\nprint(f\"Percentage kept: {(balanced_data['text'].str.len() <= 320).sum() / len(balanced_data) * 100:.1f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:24.948975Z","iopub.execute_input":"2025-09-29T08:59:24.949258Z","iopub.status.idle":"2025-09-29T08:59:25.005606Z","shell.execute_reply.started":"2025-09-29T08:59:24.949237Z","shell.execute_reply":"2025-09-29T08:59:25.004544Z"}},"outputs":[{"name":"stdout","text":"Samples under 320 chars: 2520\nSamples over 320 chars: 17186\nPercentage kept: 12.8%\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"PHASE 4: TRAIN/VALIDATION/TEST SPLIT\")\nprint(\"=\"*80)\n\nfrom sklearn.model_selection import train_test_split\n\n# Step 1: First split - separate test set (10%)\nprint(\"\\nStep 1: Splitting dataset into train+val (90%) and test (10%)...\")\ntrain_val_data, test_data = train_test_split(\n    balanced_data, \n    test_size=0.10, \n    random_state=42,\n    stratify=balanced_data['label']\n)\nprint(f\"✓ Train+Val size: {len(train_val_data)}\")\nprint(f\"✓ Test size: {len(test_data)}\")\n\n# Step 2: Second split - separate validation set from training (10% of total = 11.11% of train_val)\nprint(\"\\nStep 2: Splitting train+val into train (80%) and validation (10%)...\")\ntrain_data, val_data = train_test_split(\n    train_val_data, \n    test_size=0.1111,  # 10% of total dataset = 11.11% of 90%\n    random_state=42,\n    stratify=train_val_data['label']\n)\nprint(f\"✓ Train size: {len(train_data)}\")\nprint(f\"✓ Validation size: {len(val_data)}\")\n\n# Step 3: Verify the splits\nprint(\"\\n\" + \"-\"*80)\nprint(\"SPLIT VERIFICATION:\")\nprint(\"-\"*80)\nprint(f\"\\nTotal dataset size: {len(balanced_data)}\")\nprint(f\"Train set size: {len(train_data)} ({len(train_data)/len(balanced_data)*100:.1f}%)\")\nprint(f\"Validation set size: {len(val_data)} ({len(val_data)/len(balanced_data)*100:.1f}%)\")\nprint(f\"Test set size: {len(test_data)} ({len(test_data)/len(balanced_data)*100:.1f}%)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:25.006539Z","iopub.execute_input":"2025-09-29T08:59:25.006833Z","iopub.status.idle":"2025-09-29T08:59:25.037349Z","shell.execute_reply.started":"2025-09-29T08:59:25.006811Z","shell.execute_reply":"2025-09-29T08:59:25.036199Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nPHASE 4: TRAIN/VALIDATION/TEST SPLIT\n================================================================================\n\nStep 1: Splitting dataset into train+val (90%) and test (10%)...\n✓ Train+Val size: 17735\n✓ Test size: 1971\n\nStep 2: Splitting train+val into train (80%) and validation (10%)...\n✓ Train size: 15764\n✓ Validation size: 1971\n\n--------------------------------------------------------------------------------\nSPLIT VERIFICATION:\n--------------------------------------------------------------------------------\n\nTotal dataset size: 19706\nTrain set size: 15764 (80.0%)\nValidation set size: 1971 (10.0%)\nTest set size: 1971 (10.0%)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"\n# Step 4: Check class distribution in each split\nprint(\"\\n\" + \"-\"*80)\nprint(\"CLASS DISTRIBUTION IN EACH SPLIT:\")\nprint(\"-\"*80)\n\nprint(\"\\nTrain set:\")\nprint(train_data['label'].value_counts().sort_index())\nprint(f\"Human (0): {(train_data['label'] == 0).sum()} ({(train_data['label'] == 0).sum()/len(train_data)*100:.1f}%)\")\nprint(f\"AI (1): {(train_data['label'] == 1).sum()} ({(train_data['label'] == 1).sum()/len(train_data)*100:.1f}%)\")\n\nprint(\"\\nValidation set:\")\nprint(val_data['label'].value_counts().sort_index())\nprint(f\"Human (0): {(val_data['label'] == 0).sum()} ({(val_data['label'] == 0).sum()/len(val_data)*100:.1f}%)\")\nprint(f\"AI (1): {(val_data['label'] == 1).sum()} ({(val_data['label'] == 1).sum()/len(val_data)*100:.1f}%)\")\n\nprint(\"\\nTest set:\")\nprint(test_data['label'].value_counts().sort_index())\nprint(f\"Human (0): {(test_data['label'] == 0).sum()} ({(test_data['label'] == 0).sum()/len(test_data)*100:.1f}%)\")\nprint(f\"AI (1): {(test_data['label'] == 1).sum()} ({(test_data['label'] == 1).sum()/len(test_data)*100:.1f}%)\")\n\n# Step 5: Reset indices for clean datasets\nprint(\"\\n\" + \"-\"*80)\nprint(\"FINALIZING SPLITS:\")\nprint(\"-\"*80)\ntrain_data = train_data.reset_index(drop=True)\nval_data = val_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)\nprint(\"✓ Indices reset for all splits\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:25.038277Z","iopub.execute_input":"2025-09-29T08:59:25.038520Z","iopub.status.idle":"2025-09-29T08:59:25.156565Z","shell.execute_reply.started":"2025-09-29T08:59:25.038501Z","shell.execute_reply":"2025-09-29T08:59:25.155744Z"}},"outputs":[{"name":"stdout","text":"\n--------------------------------------------------------------------------------\nCLASS DISTRIBUTION IN EACH SPLIT:\n--------------------------------------------------------------------------------\n\nTrain set:\nlabel\n0    7882\n1    7882\nName: count, dtype: int64\nHuman (0): 7882 (50.0%)\nAI (1): 7882 (50.0%)\n\nValidation set:\nlabel\n0    985\n1    986\nName: count, dtype: int64\nHuman (0): 985 (50.0%)\nAI (1): 986 (50.0%)\n\nTest set:\nlabel\n0    986\n1    985\nName: count, dtype: int64\nHuman (0): 986 (50.0%)\nAI (1): 985 (50.0%)\n\n--------------------------------------------------------------------------------\nFINALIZING SPLITS:\n--------------------------------------------------------------------------------\n✓ Indices reset for all splits\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"\n# Sample from each split\nprint(\"\\n\" + \"-\"*80)\nprint(\"SAMPLE FROM EACH SPLIT:\")\nprint(\"-\"*80)\nprint(\"\\nTrain set sample:\")\nprint(train_data.head(3))\nprint(\"\\nValidation set sample:\")\nprint(val_data.head(3))\nprint(\"\\nTest set sample:\")\nprint(test_data.head(3))\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 4 COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"✓ Data split into train/val/test with 80/10/10 ratio\")\nprint(f\"✓ Both classes proportionally represented in all splits\")\nprint(f\"✓ Ready for tokenization in Phase 5\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:25.157691Z","iopub.execute_input":"2025-09-29T08:59:25.157978Z","iopub.status.idle":"2025-09-29T08:59:25.186712Z","shell.execute_reply.started":"2025-09-29T08:59:25.157955Z","shell.execute_reply":"2025-09-29T08:59:25.185596Z"}},"outputs":[{"name":"stdout","text":"\n--------------------------------------------------------------------------------\nSAMPLE FROM EACH SPLIT:\n--------------------------------------------------------------------------------\n\nTrain set sample:\n                                                text  label  text_length\n0  Twitch Plays Pokemon is a live stream event th...      1          964\n1  If you were to eat pure nutrients and no super...      1          606\n2  Back when giant lizards roam the earth , keybo...      0          998\n\nValidation set sample:\n                                                text  label  text_length\n0  A minimum purchase quantity just means that yo...      0          490\n1  I * think * what you are taking about is a tes...      0          432\n2  Harvard Business School (HBS) is a graduate bu...      1          856\n\nTest set sample:\n                                                text  label  text_length\n0  Defibrillators are used to try to restart a pe...      1          998\n1  When you close your eyes hard, you might hear ...      1          402\n2  ELI20 : We do n't hear our voice in a lower pi...      0          833\n\n================================================================================\nPHASE 4 COMPLETE!\n================================================================================\n✓ Data split into train/val/test with 80/10/10 ratio\n✓ Both classes proportionally represented in all splits\n✓ Ready for tokenization in Phase 5\n================================================================================\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"PHASE 5: TOKENIZATION\")\nprint(\"=\"*80)\n\nfrom transformers import RobertaTokenizer\n\n# Step 1: Load the pretrained RoBERTa tokenizer\nprint(\"\\nStep 1: Loading RoBERTa tokenizer (roberta-large-openai-detector)...\")\ntokenizer = RobertaTokenizer.from_pretrained('roberta-large-openai-detector')\nprint(\"✓ Tokenizer loaded successfully\")\n\n# Step 2: Check average token length to determine max_length\nprint(\"\\nStep 2: Analyzing token lengths to determine max_length...\")\nsample_texts = train_data['text'].head(100).tolist()\nsample_tokens = [len(tokenizer.encode(text)) for text in sample_texts]\navg_tokens = sum(sample_tokens) / len(sample_tokens)\nmax_tokens = max(sample_tokens)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T08:59:25.187675Z","iopub.execute_input":"2025-09-29T08:59:25.188035Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nPHASE 5: TOKENIZATION\n================================================================================\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"train_data['text']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(f\"Average tokens in sample: {avg_tokens:.0f}\")\nprint(f\"Max tokens in sample: {max_tokens}\")\nprint(f\"Recommended max_length: 256 tokens (suitable for ~320 character texts)\")\n\n# Step 3: Tokenize all datasets\nprint(\"\\nStep 3: Tokenizing train, validation, and test sets...\")\n\nmax_length = 500\n\ntrain_encodings = tokenizer(\n    train_data['text'].tolist(),\n    truncation=True,\n    padding='max_length',\n    max_length=max_length,\n    return_tensors='pt'\n)\n\nval_encodings = tokenizer(\n    val_data['text'].tolist(),\n    truncation=True,\n    padding='max_length',\n    max_length=max_length,\n    return_tensors='pt'\n)\n\ntest_encodings = tokenizer(\n    test_data['text'].tolist(),\n    truncation=True,\n    padding='max_length',\n    max_length=max_length,\n    return_tensors='pt'\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(f\"✓ Train set tokenized: {len(train_encodings['input_ids'])} samples\")\nprint(f\"✓ Validation set tokenized: {len(val_encodings['input_ids'])} samples\")\nprint(f\"✓ Test set tokenized: {len(test_encodings['input_ids'])} samples\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Pick a sample text\nsample_text = train_data['text'].iloc[0]\n\n# Encode using tokenizer\nencoded = tokenizer.encode(sample_text, truncation=True, max_length=256)\nprint(\"Token IDs:\", encoded[:30])  # first 30 token IDs\n\n# Decode first few tokens back to text\ndecoded = tokenizer.decode(encoded[:30])\nprint(\"Decoded tokens:\", decoded)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"PHASE 6: LOAD PRETRAINED MODEL\")\nprint(\"=\"*80)\n\nfrom transformers import RobertaForSequenceClassification\nimport torch\n\n# Step 1: Check if GPU is available\nprint(\"\\nStep 1: Checking device availability...\")\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"✓ Using device: {device}\")\nif torch.cuda.is_available():\n    print(f\"✓ GPU Name: {torch.cuda.get_device_name(0)}\")\n    print(f\"✓ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n\n# Step 2: Load the pretrained RoBERTa model\nprint(\"\\nStep 2: Loading roberta-large-openai-detector model...\")\nmodel = RobertaForSequenceClassification.from_pretrained(\n    'roberta-large-openai-detector',\n    num_labels=2\n)\nprint(\"✓ Model loaded successfully\")\n\n# Step 3: Move model to device\nprint(\"\\nStep 3: Moving model to device...\")\nmodel = model.to(device)\nprint(f\"✓ Model moved to {device}\")\n\n# Step 4: Display model information\nprint(\"\\n\" + \"-\"*80)\nprint(\"MODEL INFORMATION:\")\nprint(\"-\"*80)\nprint(f\"Model name: roberta-large-openai-detector\")\nprint(f\"Model type: RobertaForSequenceClassification\")\nprint(f\"Number of labels: 2 (0=Human, 1=AI)\")\nprint(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\nprint(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n\n# Step 5: Model architecture summary\nprint(\"\\n\" + \"-\"*80)\nprint(\"MODEL ARCHITECTURE:\")\nprint(\"-\"*80)\nprint(model.config)\n\n# Step 6: Verify model is ready\nprint(\"\\n\" + \"-\"*80)\nprint(\"MODEL STATUS:\")\nprint(\"-\"*80)\nprint(f\"✓ Model is in training mode: {model.training}\")\nprint(f\"✓ Model device: {next(model.parameters()).device}\")\nprint(f\"✓ Model dtype: {next(model.parameters()).dtype}\")\n\n# Step 7: Create PyTorch datasets\nprint(\"\\n\" + \"-\"*80)\nprint(\"CREATING PYTORCH DATASETS:\")\nprint(\"-\"*80)\n\nclass TextDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: val[idx] for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = TextDataset(train_encodings, train_labels)\nval_dataset = TextDataset(val_encodings, val_labels)\ntest_dataset = TextDataset(test_encodings, test_labels)\n\nprint(f\"✓ Train dataset created: {len(train_dataset)} samples\")\nprint(f\"✓ Validation dataset created: {len(val_dataset)} samples\")\nprint(f\"✓ Test dataset created: {len(test_dataset)} samples\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PHASE 6 COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"✓ Model loaded and ready for fine-tuning\")\nprint(f\"✓ PyTorch datasets created\")\nprint(f\"✓ Ready for training in Phase 7\")\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"PHASE 7: FINE-TUNING\")\nprint(\"=\"*80)\n\nfrom transformers import Trainer, TrainingArguments, TrainerCallback\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\n\n# Step 1: Define evaluation metrics\nprint(\"\\nStep 1: Setting up evaluation metrics...\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n\nprint(\"✓ Metrics configured: accuracy, precision, recall, F1-score\")\n\n# Step 2: Define training arguments with techniques to prevent overfitting\nprint(\"\\nStep 2: Configuring training arguments...\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16,\n    warmup_steps=500,\n    weight_decay=0.01,\n    learning_rate=2e-5,\n    logging_dir='./logs',\n    logging_steps=100,\n    eval_strategy='steps', \n    eval_steps=500,\n    save_strategy='steps',\n    save_steps=500,\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n    fp16=torch.cuda.is_available(),\n    report_to='none',\n    disable_tqdm=False\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nprint(\"✓ Training configuration:\")\nprint(f\"  - Epochs: {training_args.num_train_epochs}\")\nprint(f\"  - Batch size (train): {training_args.per_device_train_batch_size}\")\nprint(f\"  - Batch size (eval): {training_args.per_device_eval_batch_size}\")\nprint(f\"  - Learning rate: {training_args.learning_rate}\")\nprint(f\"  - Weight decay: {training_args.weight_decay}\")\nprint(f\"  - Warmup steps: {training_args.warmup_steps}\")\nprint(f\"  - Early stopping: Load best model at end (based on F1)\")\nprint(f\"  - FP16: {training_args.fp16}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Step 3: Create Trainer\nprint(\"\\nStep 3: Creating Trainer...\")\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(\"✓ Trainer initialized\")\n\n# Step 4: Start training\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING TRAINING...\")\nprint(\"=\"*80)\nprint(\"Note: Training progress with loading bars will be shown below\\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"=\"*80)\nprint(\"PHASE 7: FINE-TUNING\")\nprint(\"=\"*80)\n\nimport torch\nfrom transformers import Trainer, TrainingArguments, TrainerCallback\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport os\n\n# First, let's check GPU availability and force GPU usage\nprint(\"\\n🔍 GPU CHECK:\")\nprint(\"=\"*50)\nif torch.cuda.is_available():\n    device_count = torch.cuda.device_count()\n    current_device = torch.cuda.current_device()\n    device_name = torch.cuda.get_device_name(current_device)\n    print(f\"✅ CUDA Available: True\")\n    print(f\"✅ GPU Count: {device_count}\")\n    print(f\"✅ Current GPU: {current_device}\")\n    print(f\"✅ GPU Name: {device_name}\")\n    print(f\"✅ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n    \n    # Move model to GPU explicitly\n    model = model.to('cuda')\n    print(f\"✅ Model moved to GPU\")\nelse:\n    print(\"❌ CUDA not available - using CPU\")\n    device_name = \"CPU\"\n\nprint(\"=\"*50)\n\n# Step 1: Define evaluation metrics\nprint(\"\\nStep 1: Setting up evaluation metrics...\")\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n\nprint(\"✓ Metrics configured: accuracy, precision, recall, F1-score\")\n\n# Step 2: Enhanced training arguments with better progress tracking\nprint(\"\\nStep 2: Configuring training arguments...\")\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=16 if torch.cuda.is_available() else 8,  # Larger batch for GPU\n    per_device_eval_batch_size=32 if torch.cuda.is_available() else 16,  # Larger batch for eval\n    warmup_steps=500,\n    weight_decay=0.01,\n    learning_rate=2e-5,\n    logging_dir='./logs',\n    logging_steps=25,  # Log more frequently to see progress\n    eval_strategy='steps', \n    eval_steps=250,  # Evaluate more frequently\n    save_strategy='steps',\n    save_steps=250,\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n    fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n    report_to='none',\n    disable_tqdm=False,  # Enable tqdm\n    logging_first_step=True,\n    dataloader_pin_memory=torch.cuda.is_available(),  # Pin memory for GPU\n    dataloader_num_workers=0,  # Important for Kaggle/Jupyter\n    remove_unused_columns=False,\n)\n\nprint(f\"✓ Training configured for {device_name}\")\nprint(f\"✓ Batch size: {training_args.per_device_train_batch_size}\")\nprint(f\"✓ Mixed precision: {training_args.fp16}\")\n\n# Enhanced progress callback with better visibility\nclass EnhancedProgressCallback(TrainerCallback):\n    def __init__(self):\n        self.training_bar = None\n        self.current_epoch = 0\n        self.total_steps = 0\n        \n    def on_train_begin(self, args, state, control, **kwargs):\n        self.total_steps = state.max_steps\n        print(f\"\\n{'🚀 TRAINING STARTED'}\")\n        print(f\"{'='*80}\")\n        print(f\"📊 Total Steps: {self.total_steps}\")\n        print(f\"📊 Epochs: {args.num_train_epochs}\")\n        print(f\"📊 Batch Size: {args.per_device_train_batch_size}\")\n        print(f\"📊 Learning Rate: {args.learning_rate}\")\n        print(f\"📊 Device: {next(kwargs['model'].parameters()).device}\")\n        print(f\"{'='*80}\\n\")\n        \n        # Create a manual progress bar\n        self.training_bar = tqdm(\n            total=self.total_steps, \n            desc=\"🔥 Training Progress\",\n            bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]',\n            ncols=100\n        )\n        \n    def on_epoch_begin(self, args, state, control, **kwargs):\n        epoch = int(state.epoch) if state.epoch is not None else 0\n        if epoch != self.current_epoch:\n            self.current_epoch = epoch\n            print(f\"\\n📈 EPOCH {epoch + 1}/{args.num_train_epochs}\")\n            print(f\"{'-'*60}\")\n        \n    def on_step_end(self, args, state, control, **kwargs):\n        if self.training_bar:\n            self.training_bar.update(1)\n            \n    def on_log(self, args, state, control, logs=None, **kwargs):\n        if logs and 'loss' in logs:\n            # Update progress bar description with current loss\n            current_loss = logs['loss']\n            if self.training_bar:\n                self.training_bar.set_postfix({\n                    'loss': f'{current_loss:.4f}',\n                    'lr': f\"{logs.get('learning_rate', 0):.2e}\",\n                    'epoch': f\"{int(state.epoch) if state.epoch else 0 + 1}\"\n                })\n    \n    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n        if metrics:\n            print(f\"\\n{'📊 VALIDATION RESULTS'}\")\n            print(f\"{'='*60}\")\n            print(f\"🎯 Accuracy:  {metrics.get('eval_accuracy', 0):.4f}\")\n            print(f\"🎯 Precision: {metrics.get('eval_precision', 0):.4f}\")\n            print(f\"🎯 Recall:    {metrics.get('eval_recall', 0):.4f}\")\n            print(f\"🎯 F1-Score:  {metrics.get('eval_f1', 0):.4f}\")\n            print(f\"📉 Loss:      {metrics.get('eval_loss', 0):.4f}\")\n            print(f\"{'='*60}\\n\")\n    \n    def on_train_end(self, args, state, control, **kwargs):\n        if self.training_bar:\n            self.training_bar.close()\n        print(f\"\\n{'✅ TRAINING COMPLETED!'}\")\n        print(f\"{'='*80}\")\n\n# Create trainer with enhanced callback\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n    callbacks=[EnhancedProgressCallback()]\n)\n\nprint(\"✓ Trainer initialized with enhanced progress tracking\")\nprint(f\"✓ Logging every {training_args.logging_steps} steps\")\nprint(f\"✓ Evaluation every {training_args.eval_steps} steps\")\n\n# Additional progress info before training\ntotal_steps = len(train_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs\nprint(f\"✓ Estimated total training steps: {total_steps}\")\nprint(f\"✓ Steps per epoch: ~{len(train_dataset) // training_args.per_device_train_batch_size}\")\n\nprint(f\"\\n{'🔥 STARTING TRAINING...'}\")\nprint(\"=\"*80)\n\n# Train the model\ntrain_result = trainer.train()\n\n# Step 5: Display final training results\nprint(\"\\n\" + \"=\"*80)\nprint(\"🎉 TRAINING COMPLETED!\")\nprint(\"=\"*80)\nprint(\"\\n📊 Final Training Metrics:\")\nprint(f\"  ⏱️  Total training time: {train_result.metrics['train_runtime']:.2f} seconds\")\nprint(f\"  ⚡ Training samples/sec: {train_result.metrics['train_samples_per_second']:.2f}\")\nprint(f\"  📉 Final training loss: {train_result.metrics['train_loss']:.4f}\")\n\n# Step 6: Final evaluation on validation set\nprint(\"\\n\" + \"=\"*80)\nprint(\"📊 FINAL VALIDATION EVALUATION...\")\nprint(\"=\"*80)\n\nval_results = trainer.evaluate(eval_dataset=val_dataset)\n\nprint(\"\\n✨ Final Validation Results:\")\nprint(f\"  🎯 Accuracy:  {val_results['eval_accuracy']:.4f}\")\nprint(f\"  🎯 Precision: {val_results['eval_precision']:.4f}\")\nprint(f\"  🎯 Recall:    {val_results['eval_recall']:.4f}\")\nprint(f\"  🎯 F1-Score:  {val_results['eval_f1']:.4f}\")\nprint(f\"  📉 Loss:      {val_results['eval_loss']:.4f}\")\n\n# Step 7: Save the fine-tuned model (save to Kaggle appropriate directory)\nprint(\"\\n\" + \"=\"*80)\nprint(\"💾 SAVING MODEL...\")\nprint(\"=\"*80)\n\n# For Kaggle, save to the working directory or model directory\nmodel_save_path = '/kaggle/working/fine_tuned_model'\nmodel.save_pretrained(model_save_path)\ntokenizer.save_pretrained(model_save_path)\n\nprint(f\"\\n✅ Model saved to '{model_save_path}'\")\nprint(f\"✅ Tokenizer saved to '{model_save_path}'\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"🎉 PHASE 7 COMPLETE!\")\nprint(\"=\"*80)\nprint(f\"✅ Model fine-tuned for {training_args.num_train_epochs} epochs\")\nprint(f\"✅ Used device: {next(model.parameters()).device}\")\nprint(f\"✅ Best model loaded based on validation F1-score\")\nprint(f\"✅ Model and tokenizer saved to Kaggle working directory\")\nprint(f\"✅ Ready for evaluation on test set in Phase 8\")\nprint(\"=\"*80)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}